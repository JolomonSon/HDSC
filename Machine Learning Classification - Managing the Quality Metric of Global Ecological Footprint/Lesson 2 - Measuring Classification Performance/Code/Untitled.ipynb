{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2df5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c693600",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[1;32m----> 2\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(\u001b[43mlog_reg\u001b[49m, normalised_train_df, y_balanced, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log_reg' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg, normalised_train_df, y_balanced, cv=5, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "kf.split(normalised_train_df)\n",
    "f1_scores = []\n",
    "# running for every split\n",
    "for train_index, test_index in kf.split(normalised_train_df):\n",
    "    x_train, x_test = normalised_train_df.iloc[train_index], normalised_train_df[test_index]\n",
    "    y_train, y_test = y_balanced[train_index], y_balanced[test_index]\n",
    "    \n",
    "    model = LogisticRegression().fit(x_train, y_train)\n",
    "    \n",
    "    #Appending result to f1_scores list\n",
    "    f1_scoers.append(f1_score(y_true=y_test, y_pred=model.predict(x_test), pos_label='2A')*100')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f34c8ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalised_train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# running for every split\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m skf\u001b[38;5;241m.\u001b[39msplit(\u001b[43mnormalised_train_df\u001b[49m, y_balanced):\n\u001b[0;32m      7\u001b[0m     x_train, x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(normalised_train_df)[train_index],np\u001b[38;5;241m.\u001b[39marray(normalised_train_df)[test_index]\n\u001b[0;32m      8\u001b[0m     y_train, y_test \u001b[38;5;241m=\u001b[39m y_balanced[train_index], y_balanced[test_index]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalised_train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Stratified K-Fold Cross Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "f1_scores = []\n",
    "# running for every split\n",
    "for train_index, test_index in skf.split(normalised_train_df, y_balanced):\n",
    "    x_train, x_test = np.array(normalised_train_df)[train_index],np.array(normalised_train_df)[test_index]\n",
    "    y_train, y_test = y_balanced[train_index], y_balanced[test_index]\n",
    "    \n",
    "    model = LogisticRegression().fit(x_train, y_train)\n",
    "    \n",
    "    # Appending result to f1_scores list\n",
    "    f1_scores.append(f1_score(y_true=y_test, y_pred=model.predict(x_test), pos_label='2A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3fb6863",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LeaveOneOut\n\u001b[0;32m      3\u001b[0m loo \u001b[38;5;241m=\u001b[39m LeaveOneOut()\n\u001b[1;32m----> 4\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(\u001b[43mLogisticRegression\u001b[49m(), normalised_train_df, y_balanced, cv\u001b[38;5;241m=\u001b[39mloo, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m average_score \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# Leave One Out Cross Validation (LOOCV)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(LogisticRegression(), normalised_train_df, y_balanced, cv=loo, scoring='f1_macro')\n",
    "average_score = scores.mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "707ca6c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Confusion Matrix\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n\u001b[1;32m----> 3\u001b[0m new_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mlog_reg\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(normalised_test_df)\n\u001b[0;32m      4\u001b[0m cnf_mat \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true\u001b[38;5;241m=\u001b[39my_test, y_pred\u001b[38;5;241m=\u001b[39mnew_predictions, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2A\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3A\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m cnf_mat\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log_reg' is not defined"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "new_predictions = log_reg.predict(normalised_test_df)\n",
    "cnf_mat = confusion_matrix(y_true=y_test, y_pred=new_predictions, labels=['2A','3A'])\n",
    "cnf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13383562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=new_predictions)\n",
    "print('Accuracy: {}'.format(round(accuracy*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "precision = precision_score(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print('Precision: {}'.format(round(precision*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e882100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "recall = recall_score(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print('Recall: {}'.format(round(recall*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-Score\n",
    "f1 = f1_score(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print('F1: {}'.format(round(f1*100), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
